{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ozalcZj6GnO"
   },
   "source": [
    "# BA 820 Homework 3 (100 Points)\n",
    "\n",
    "## 1 Latent Dirichlet Allocation [60pts]\n",
    "\n",
    "In this problem, we will use Latent Dirichlet Allocation to perform topic modeling on Amazon Review datasets. In particular, we will take an in-depth look at different aspects of LDA model.\n",
    "\n",
    "## 1.1 Installation\n",
    "\n",
    "To perform LDA and visualize, please use Python 3.X. You will also need to install Numpy, Scipy, gensim, nltk, pyLDAvis library. Refer to requirements.txt for more details.\n",
    "Use the following code to install the labraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7m0zKTQLP-a",
    "outputId": "4fff6eec-b621-4551-abbf-cb0724ba450b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.24.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyldavis in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (3.4.0)\n",
      "Requirement already satisfied: funcy in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (1.18)\n",
      "Requirement already satisfied: jinja2 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (1.24.2)\n",
      "Requirement already satisfied: gensim in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (4.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (63.4.1)\n",
      "Requirement already satisfied: numexpr in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (2.8.3)\n",
      "Requirement already satisfied: pandas>=1.3.4 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (1.4.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (1.2.1)\n",
      "Requirement already satisfied: scipy in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pyldavis) (1.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.3.4->pyldavis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.3.4->pyldavis) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.0->pyldavis) (2.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from gensim->pyldavis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from jinja2->pyldavis) (2.0.1)\n",
      "Requirement already satisfied: packaging in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from numexpr->pyldavis) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyldavis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from packaging->numexpr->pyldavis) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (3.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nini/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "# install gensim for LDA\n",
    "%pip install nltk \n",
    "# install nltk to preprocess sentences\n",
    "%pip install pyldavis\n",
    "# to visualize LDA topics\n",
    "%pip install matplotlib \n",
    "# for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFDfBgMF6Rsu"
   },
   "source": [
    "The cell below tests if the packages we need have been installed correctly, and that we are in the correct environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iRwy_ck6SLL",
    "outputId": "f9828d0a-1c5a-40b8-d51a-1a3a8ba2c668"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/nini/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_punctuation, strip_numeric\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "import pyLDAvis\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import gzip # to unzip the data\n",
    "import re # to replace punctuations\n",
    "from nltk.corpus import stopwords # list of stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLu3zAuv6m0r"
   },
   "source": [
    "## 1.2 Datasets\n",
    "\n",
    "You can download the Amazon reviews dataset of Cellphones & Accessory 5-Core Data [here](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz). Place the downloaded dataset in the same folder as this notebook. You can use the following code to read a datat from GZIp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gbSEVGKw6nV7"
   },
   "outputs": [],
   "source": [
    "# A function to read the zipped data at a specfic path\n",
    "#\n",
    "# How to use:\n",
    "# PATH = \"/path/to/file\"\n",
    "# for line in parse(PATH):\n",
    "#   do something with line\n",
    "#\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B48OODRf70mY"
   },
   "source": [
    "## 1.3 Data Cleaning\n",
    "\n",
    "Now we will preprocess the data using the following steps:\n",
    "   1. Remove stopwords\n",
    "   2. Lower-case all words\n",
    "   3. Remove words with less than 2 characters\n",
    "   4. Remove punctuation\n",
    "   5. Split each sentence into a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6JVvT5kh7qO9"
   },
   "outputs": [],
   "source": [
    "# A function to clean a single line of text\n",
    "def clean_line(line):\n",
    "    \"\"\" Clean stopwords and punction for each line\n",
    "    \n",
    "    Args: \n",
    "        line (string): one line in file\n",
    "        \n",
    "    Returns:\n",
    "        list(str): a list of all words in the sentence\n",
    "    \"\"\"\n",
    "    punctuationRegex = r'\\W+|\\d+'\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    line = line.split(\" \")\n",
    "    filtered_content = []\n",
    "    for word in line:\n",
    "        ### Solution ###\n",
    "        \n",
    "        # lowercase all words and remove stopwords and punctuation\n",
    "        for w in word.lower().split():\n",
    "            w = re.sub(punctuationRegex, \"\", w)\n",
    "            if w not in stopWords:\n",
    "                # remove words with less than 2 characters\n",
    "                if len(w) >= 2:\n",
    "                    filtered_content.append(w)\n",
    "        ###\n",
    "    return filtered_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYnnn1KC8jZ8"
   },
   "source": [
    "Finally, we put parse() and clean_line() function together and then extract the first 10,000 reviews into a new text file as your experiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FXjJSwnD8jvK"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def read_dataset(fname):\n",
    "    \"\"\" Read the 10000 lines in given dataset into list and clean stop words. \n",
    "        \n",
    "    Args: \n",
    "        fname (string): filename of Amazon Review Dataset\n",
    "        \n",
    "    Returns:\n",
    "        list of list of words: we view each document as a list, including a list of all words \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    exp_dataset = []\n",
    "    for review in parse(fname):\n",
    "        line = review[\"reviewText\"]\n",
    "        new_line = clean_line(line)\n",
    "        exp_dataset.append(new_line)\n",
    "        count += 1\n",
    "        if count > 10000:\n",
    "            break\n",
    "    return exp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "4cRY1JaN8mIM",
    "outputId": "2459c5d6-066c-4fad-c5e5-35f435845005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['look', 'good', 'stick', 'good', 'dont', 'like', 'rounded', 'shape', 'always', 'bumping', 'siri', 'kept', 'popping', 'irritating', 'wont', 'buy', 'product', 'like']\n",
      "CPU times: user 3.81 s, sys: 435 ms, total: 4.24 s\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = read_dataset(\"reviews_Cell_Phones_and_Accessories_5.json.gz\")\n",
    "print(r[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FQFnMjb8l1B"
   },
   "source": [
    "## 1.4 Topic Analysis\n",
    "\n",
    "**[5pts] Q1.4.1.1** Use topic numbers 3, 6, 9, 12, 15 respectively and print out all topics with 5 words.\n",
    "\n",
    "For this We will use gensim to train an LDA model. gensim requires the following steps:\n",
    "\n",
    "Construct a gensim.corpora.dictionary from the dataset\n",
    "Construct a gensim \"corpus\" using this dictionary, by mapping each word to an index in the dictionary\n",
    "Run LDA on this corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JzfOjF9I9kDD"
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(r)\n",
    "corpus = [dictionary.doc2bow(text) for text in r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xblcs_6-99gp"
   },
   "source": [
    "The function below prints the top num words in each topic for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "b_NopMJj951v"
   },
   "outputs": [],
   "source": [
    "def print_topic_words(model, num):\n",
    "    \"\"\" print top words in model topics.\n",
    "    \n",
    "    Args: \n",
    "        model: LDA model\n",
    "        \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"    \n",
    "    #########################\n",
    "    words = model.print_topic(num-1, topn=5)\n",
    "    filters = [lambda x: x.lower(), strip_punctuation, strip_numeric]\n",
    "    print(f'Topic: {num} \\nWords: {preprocess_string(words, filters)}')\n",
    "\n",
    "    #########################\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56Sv1l9S-JeI"
   },
   "source": [
    "The following function builds multiple LDA models with number of topics specified in the list `num_topics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NhGPQYTo-Jxx"
   },
   "outputs": [],
   "source": [
    "def build_num_topic_model(dictionary, corpus, num_topics):\n",
    "    \"\"\" Build lda model with given parameters, use print_topic_words to print words\n",
    "    \n",
    "    Args: \n",
    "        dictionary: dictionary built from dataset\n",
    "        corpus: corpus built from dataset\n",
    "        num_topics: list of numbers\n",
    "        \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"    \n",
    "    for num in num_topics:\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=num, \n",
    "                                               random_state=100,\n",
    "                                               #update_every=1,\n",
    "                                               #chunksize=100,\n",
    "                                               #passes=10,\n",
    "                                               alpha='auto',\n",
    "                                               #per_word_topics=True\n",
    "                                                   )                                        \n",
    "        print_topic_words(lda_model, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "k8NtFThx-Od0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 3 \n",
      "Words: ['case', 'mophie', 'doubles', 'iphone', 'bottom']\n",
      "Topic: 6 \n",
      "Words: ['phone', 'charger', 'great', 'one', 'use']\n",
      "Topic: 9 \n",
      "Words: ['phone', 'camera', 'phones', 'nokia', 'screen']\n",
      "Topic: 12 \n",
      "Words: ['headset', 'phone', 'ear', 'sound', 'bluetooth']\n",
      "Topic: 15 \n",
      "Words: ['phone', 'use', 'would', 'like', 'one']\n"
     ]
    }
   ],
   "source": [
    "build_num_topic_model(dictionary, corpus, [3, 6, 9, 12, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8vkk6bo-UEi"
   },
   "source": [
    "**[3pts] Q1.4.1.2**  Explain what could be interpreted for each topics, and describe the similarity and difference between different topic numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRLNs647-VF7"
   },
   "source": [
    "The topics are similar in that they all relate to different aspects of mobile phone usage and accessories. However, they differ in their specific focus and purpose.\n",
    "\n",
    "- Topic 3: Mophie phone cases for iPhone models. This topic specifically focuses on a particular brand of phone cases for iPhone models.\n",
    "- Topic 6: Best phone chargers for daily use. This topic specifically focuses on the best phone chargers for daily use, regardless of the phone model.\n",
    "- Topic 9: Comparison of phone cameras and screens for Nokia phones. This topic specifically compares Nokia phone cameras and screens, rather than discussing phone accessories or other devices.\n",
    "- Topic 12: Best wireless headset for phone audio. This topic focuses on the best wireless headsets for phone audio quality, regardless of the phone model.\n",
    "- Topic 15: Choosing the right phone for your needs and preferences. This topic is broader in scope, as it covers different factors to consider when choosing a phone that suits your lifestyle and preferences, including the phone's features, plan, and carrier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERTTf2sGDIPp"
   },
   "source": [
    "**[2pts] Q1.4.1.3**  Which topic number would you choose? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOgDUPcvDLs8"
   },
   "source": [
    "I would prefer to read about Topic 6 as it addresses a problem I frequently encounter - my phone battery draining quickly. In my opinion, having a good phone charger that could extend my battery life would be very beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJfqY1reDX5s"
   },
   "source": [
    "## 1.5 Model Evaluation\n",
    "\n",
    "**[12 pts] Q1.5.1** Now we investigate two methods to evaluate our model and choose the topic number\n",
    "\n",
    "1. Perplexity is a measurement of how well a probability distribution or probability model predicts a sample. A low perplexity indicates the probability distribution is good at predicting the sample. We can use model.log_perplexity(document) to evaluate the perplexity of our LDA model.\n",
    "\n",
    "2. Topic coherence is a one type of interpretability measurement for a topic. It measures if a set of top keywords describe a coherent and singular concept. A good topic will have high topic coherence score. We can use CoherenceModel(model=ldamodel).get_coherence() to calculate it.\n",
    "\n",
    "Plot Perplexity and topic coherence scores of our LDA model for topic number 3,6,9,12,15,20,50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni7eZRSIDsIU"
   },
   "source": [
    "The code below trains topic models with different numbers of topics and measures their coherence and perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1ue1Pf4--UjO"
   },
   "outputs": [],
   "source": [
    "# perplexity \n",
    "# run different number of topics to get perplexity and coherence value for this model\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "def get_measurement_for_model(dictionary, corpus, topic_nums):\n",
    "    \"\"\" Build lda model with given parameters \n",
    "    \n",
    "    Args: \n",
    "        dictionary: dictionary built from dataset\n",
    "        corpus: corpus built from dataset\n",
    "        topic_nums: a list contains all possible topic number\n",
    "        \n",
    "    Returns:\n",
    "        2 lists: one of perplexities, and one of coherence value\n",
    "    \"\"\"  \n",
    "    perplexity = []\n",
    "    coherence_value=[]\n",
    "    for num_topic in topic_nums:\n",
    "        \n",
    "        #########################\n",
    "           # YOUR CODE HERE\n",
    "        #   - Build model\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=num_topic, \n",
    "                                               random_state=69,\n",
    "#                                                update_every=1,\n",
    "#                                                chunksize=100,\n",
    "#                                                passes=10,\n",
    "                                                alpha='auto',\n",
    "#                                                per_word_topics=True\n",
    "                                                   )\n",
    "#         build_num_topic_models(dictionary, corpus, num_topic)\n",
    "                        \n",
    "        \n",
    "        \n",
    "        #   - Compute and store coherence\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, texts=r, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        coherence_value.append(coherence_lda)\n",
    "        \n",
    "        #   - Compute and store perplexity\n",
    "        perplexity.append(lda_model.log_perplexity(corpus))\n",
    "        #########################\n",
    "    return perplexity,coherence_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nX_zj0RoD4j0"
   },
   "outputs": [],
   "source": [
    "perplexity, coherence = get_measurement_for_model(dictionary, corpus, [3, 6, 9, 12, 15, 20, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yk-ojlJSD85k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.707141384904688, -8.405065074863696, -8.79516472567271, -8.922134281252172, -9.115919765982795, -9.3848202565316, -11.341971313263757]\n",
      "[0.44607764247551884, 0.35615045903330955, 0.34308623191309073, 0.3333377882999596, 0.3550526347997419, 0.34568225490681337, 0.3520482874206474]\n"
     ]
    }
   ],
   "source": [
    "print(perplexity)\n",
    "print(coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcYTqBizD9az"
   },
   "source": [
    "We can now plot the coherence and perplexity of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1B9scv8sD_n8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "G76jh0BXECKs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/howardzonda/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/howardzonda/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 8722 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([3, 6, 9, 12, 15, 20, 50], perplexity)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUDG-rr5ELQN"
   },
   "source": [
    "**[2pts] Q1.5.2**  From the above graph what topic number would you choose and why? Is it a good idea to choose the topic number based on perplexity? why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5SLdipiENoi"
   },
   "source": [
    "If we were asked to choose on the preceding graph, we would select topic number = 50, which has the lowest perplexity score among the other numbers. But, while choosing a topic number, we also need to consider the coherence score, as even a score when topic numbers = 50 indicates low perplexity. Still, if the text is not coherent, it may not give us a topic idea. If knowing the topic is more important than how a good model fits, we should not choose topics simply based on their perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EBhTyUQdELuW"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([3, 6, 9, 12, 15, 20, 50], coherence)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Number of topics\")\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnCOd2_CEY2W"
   },
   "source": [
    "**[2pts] Q1.5.3**  From the above graph what topic number would you choose and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm5bcHV4EcOa"
   },
   "source": [
    "From the above topic we would choose topic number = 3 as it has the highest coherence score, which would help to identify the idea of topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppxl4L4cElVA"
   },
   "source": [
    "**[4pts]Q1.5.4** Compare two methods you implemented in the previous quesions, which one do you think is better and why? In answering, please discuss the actual topics generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMiQEut8Em__"
   },
   "source": [
    "Based on the two previous methods, selecting a topic based on its coherence score is better, as it will give us a better idea of the topic, and we would like to know the topic. Perplexity fits the model, and fitting the model is good, but knowing the idea, we believe, is more important. For example, topic number 3 gives us the idea that the topic is about the phone case of a brand, whereas topic number 50 gives little idea of the topic even though it has the lowest perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBkDhQzGFPyp"
   },
   "source": [
    "## 1.6 Alpha and Beta in LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jelhz4KFFgde"
   },
   "source": [
    "**[7pts]Q1.6.1** In this problem, we will check the two most important parameters in LDA model: alpha and beta. Alpha represents document-topic density - with a higher alpha, documents are made up of more topics, and with lower alpha, documents contain fewer topics. Beta represents topic-word density - with a high beta, topics are made up of most of the words in the corpus, and with a low beta they consist of few words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "x7Wr3DphEb2O"
   },
   "outputs": [],
   "source": [
    "best_topic_num = 3 # CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8AP4Hn1uFkkc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 3 \n",
      "Words: ['headset', 'ear', 'bluetooth', 'sound', 'one']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "model1 = None\n",
    "#########################\n",
    "# YOUR CODE HERE\n",
    "lda_model_1 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=best_topic_num, \n",
    "                                               random_state=69,\n",
    "#                                                update_every=1,\n",
    "#                                                chunksize=100,\n",
    "#                                                passes=10,\n",
    "                                               alpha=1/best_topic_num, eta =best_topic_num,\n",
    "#                                                per_word_topics=True\n",
    "                                             )\n",
    "\n",
    "# words = lda_model_1.print_topic(best_topic_num-1, topn=5)\n",
    "print(print_topic_words(lda_model_1, best_topic_num))\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3WDzHIzGFm7v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 3 \n",
      "Words: ['case', 'iphone', 'mophie', 'battery', 'doubles']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model 2\n",
    "model2 = None\n",
    "#########################\n",
    "# YOUR CODE HERE\n",
    "lda_model_2 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=best_topic_num, \n",
    "                                               random_state=69,\n",
    "#                                                update_every=1,\n",
    "#                                                chunksize=100,\n",
    "#                                                passes=10,\n",
    "                                               alpha=1/2, eta = 1/5,\n",
    "#                                                per_word_topics=True\n",
    "                                             )\n",
    "\n",
    "print(print_topic_words(lda_model_2, best_topic_num))\n",
    "\n",
    "#   - Build model for alpha = 1/2, eta = 1/5\n",
    "#   - Print top words\n",
    "#########################\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "hhM9efkXFqI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 3 \n",
      "Words: ['case', 'mophie', 'iphone', 'doubles', 'shed']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model 3\n",
    "model3 = None\n",
    "#########################\n",
    "lda_model_3 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=best_topic_num, \n",
    "                                               random_state=69,\n",
    "#                                                update_every=1,\n",
    "#                                                chunksize=100,\n",
    "#                                                passes=10,\n",
    "                                               alpha= 'auto', eta = 'auto',\n",
    "#                                                per_word_topics=True\n",
    "                                             )\n",
    "\n",
    "print(print_topic_words(lda_model_3, best_topic_num))\n",
    "\n",
    "\n",
    "#   - Build model for alpha = 'auto' = eta\n",
    "#   - Print top words\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRIg6fAIFwW0"
   },
   "source": [
    "**[3pts]1.6.2**  Explain how the different alpha and beta values theoretically influence the LDA model. Then describe what you find in the empirical result (e.g difference in topic words and topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QU26drlOFxo1"
   },
   "source": [
    "Alpha is a hyperparameter that assigns topics to documents. It affects the probability of a document having a specific topic. Specifically, a high alpha value encourages documents to contain a mixture of more topics, while a low alpha value encourages documents to be dominated by a smaller set of topics. So, if we have a low alpha in setting we might get more specific topics, whereas setting it to a high value can result in more general and diverse topics.\n",
    "\n",
    "Beta influences the probability of a topic containing a particular word. A high beta value allows topics to contain a mixture of more words, while a low beta value allows topics to have a smaller set of words. So, setting beta to a low value can result in more distinct and coherent topics, while setting it to a high value can result in more generic and overlapping topics.\n",
    "For example, model 1 has very low alpha and give much explaination for the topic, similarly second model gives even more precise idea as it has lower beta as well compared to model1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSsPpXqXG11h"
   },
   "source": [
    "## 1.7 LDA on a short text dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbrCxteDHM1b"
   },
   "source": [
    "**[10pts]1.7.1** In this part, we will read a dataset from twitter and build a LDA model. On Windows, download and unzip the dataset from [this link](http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip). Place the downloaded dataset in the same folder as this notebook. Use the first 10,000 lines in the \"training.1600000.processed.noemoticon.csv\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eg8B4xaRFxA3",
    "outputId": "154f5451-d99a-49bb-c7ff-dbfc23565ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "unzip:  cannot find or open trainingandtestdata.zip, trainingandtestdata.zip.zip or trainingandtestdata.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip # Linux and OSX only\n",
    "!unzip trainingandtestdata.zip # Linux and OSX only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  trainingandtestdata.zip\n",
      "  inflating: testdata.manual.2009.06.14.csv  \n",
      "  inflating: training.1600000.processed.noemoticon.csv  \n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = 'http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip'\n",
    "filename = 'trainingandtestdata.zip'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "!unzip trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "81FoZvt_HTq6"
   },
   "outputs": [],
   "source": [
    "!head -n 10000 training.1600000.processed.noemoticon.csv > twitter.csv # Linux and OSX only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "z0ZS7Uvt8lgo"
   },
   "outputs": [],
   "source": [
    "def convert(character):\n",
    " \n",
    "    # initialization of string to \"\"\n",
    "    string = \"\"\n",
    " \n",
    "    # traverse in the string\n",
    "    for x in character:\n",
    "        string += x\n",
    " \n",
    "    # return string\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uJSwYJflHWvp"
   },
   "outputs": [],
   "source": [
    "def read_twitter(fname):\n",
    "    \"\"\" Read the given dataset into list and clean stop words. \n",
    "    \n",
    "    Args: \n",
    "        fname (string): filename of Twitter Dataset\n",
    "        \n",
    "    Returns:\n",
    "        list of list of words: we view each document as a list, including a list of all words \n",
    "    \"\"\"\n",
    "    twitter = []\n",
    "    with open(fname, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            tweet = line.split(\",\")[5].strip()\n",
    "            tweet_text = convert(tweet)\n",
    "            tweet = tweet.split(\" \")\n",
    "            # Remove @s and URLs\n",
    "            tweet_text = [re.sub(r'^@|[^\\w\\s]|http\\S+', '', word) for word in tweet]\n",
    "            # Remove stopwords\n",
    "            stops = stopwords.words('english')\n",
    "            stops.extend(['n\\'t', '|', '#', '\\'s', '\\\"', '\\'re', '\\'ve', '\\'ll', '\\'d', 'n', 'u'])\n",
    "            tweet_text = [word for word in tweet_text if word.lower() not in stops and word.lower() != \"\"]\n",
    "            # tweet_text = convert(tweet_text)\n",
    "            twitter += tweet_text\n",
    "\n",
    "            #for word in twitter:\n",
    "            ########################\n",
    "            # YOUR CLEANING CODE HERE\n",
    "            #    - Clean tweet\n",
    "            #    - Split into list words\n",
    "            #    - Store list in twitter\n",
    "            ########################\n",
    "    return twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1657cE1hHY8_",
    "outputId": "e9a7d5fb-68f2-48c9-c43c-c9e9fd254eb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 314 ms, total: 1.82 s\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twitter = read_twitter('twitter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YzcgFZx_HZgK"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "tweet_split = [tweet.split() for tweet in twitter]\n",
    "twitter_dictionary = corpora.Dictionary(tweet_split)# TODO: build dictionary\n",
    "twitter_corpus = [twitter_dictionary.doc2bow(tweet) for tweet in tweet_split] # TODO: build corpus for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WoNVLuJHcyu",
    "outputId": "58575742-4ca5-4dd2-b445-4e121a86afb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 16s, sys: 1.15 s, total: 2min 17s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=twitter_corpus,\n",
    "                                           id2word=twitter_dictionary,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "########################\n",
    "# YOUR CODE HERE\n",
    "#    - Build model\n",
    "#    - Print top words\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "iKiswJTJ-MGG"
   },
   "outputs": [],
   "source": [
    "def print_topic_words(model, num):\n",
    "    \"\"\" print top words in model topics.\n",
    "    \n",
    "    Args: \n",
    "        model: LDA model\n",
    "        \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"    \n",
    "    #########################\n",
    "    words = model.print_topic(num-1, topn=10)\n",
    "    filters = [lambda x: x.lower(), strip_punctuation, strip_numeric]\n",
    "    print(f'Topic: {num} \\nWords: {preprocess_string(words, filters)}')\n",
    "\n",
    "    #########################\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tN0C6Ett-Qwc",
    "outputId": "dcbe5d47-9c65-423c-bb15-e1e28bcbe6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 1 \n",
      "Words: ['im', 'watch', 'didnt', 'also', 'hurt', 'feels', 'dvds', 'bits', 'early', 'castiel']\n",
      "Topic: 2 \n",
      "Words: ['see', 'love', 'dvds', 'early', 'bits', 'dandy', 'sephy', 'spell', 'rainboot', 'stuffing', 'colleague']\n",
      "Topic: 3 \n",
      "Words: ['first', 'bit', 'shylands', 'tornadoliese', 'outmy', 'qs', 'sends', 'aweber', 'tit', 'problogger']\n",
      "Topic: 4 \n",
      "Words: ['wish', 'rainboot', 'bits', 'dvds', 'spell', 'tweeted', 'early', 'clean', 'stuffing']\n",
      "Topic: 5 \n",
      "Words: ['work', 'day', 'im', 'get', 'sad', 'today', 'going', 'night', 'dont', 'want']\n",
      "Topic: 6 \n",
      "Words: ['got', 'like', 'long', 'body', 'dvds', 'bits', 'early', 'windsor', 'castiel', 'stuffing']\n",
      "Topic: 7 \n",
      "Words: ['thought', 'many', 'might', 'aweber', 'silent', 'dave', 'shylands', 'tornadoliese', 'outmy', 'qs', 'kg']\n",
      "Topic: 8 \n",
      "Words: ['hey', 'problogger', 'whatnot', 'tornadoliese', 'outmy', 'qs', 'sends', 'aweber', 'silent', 'dave', 'realized']\n",
      "Topic: 9 \n",
      "Words: ['cant', 'always', 'wanted', 'dvds', 'bits', 'early', 'tweeted', 'castiel', 'jaws', 'windsor']\n",
      "Topic: 10 \n",
      "Words: ['go', 'cry', 'dvds', 'bits', 'early', 'stuffing', 'windsor', 'colleague', 'rainboot', 'tweeted']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "  print_topic_words(lda_model, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzced6IXOU1Z"
   },
   "source": [
    "## 1.8 LDA visualization\n",
    "\n",
    "**[10pts]1.8.1** We will now visualize the LDA output using pyLDAvis. PyLDAVis shows the following:\n",
    "\n",
    "   1. The distances between topics, as a map in 2-D space.\n",
    "   2. The variance in the topic-word distribution, as the size of a circle in this map.\n",
    "   3. The most \"salient\" terms in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Dn0msKKPJXF",
    "outputId": "81950898-c673-4d55-b8e6-c42a23cff543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.5 ms, sys: 7.18 ms, total: 15.7 ms\n",
      "Wall time: 23.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pyLDAvis\n",
    "#import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZsFH15wPLo2",
    "outputId": "3706c6ce-90b0-48ff-d407-502720b69d85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/howardzonda/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
      "/Users/howardzonda/opt/anaconda3/lib/python3.7/site-packages/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "/Users/howardzonda/opt/anaconda3/lib/python3.7/site-packages/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 s, sys: 166 ms, total: 3.42 s\n",
      "Wall time: 6.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = None\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_display = pyLDAvis.gensim_models.prepare(lda_model, twitter_corpus, twitter_dictionary)\n",
    "########################\n",
    "# YOUR CODE HERE\n",
    "#   - Initalize pyLDAvis with your model\n",
    "#   - Make sure to use a subset of the sentences in the dataset\n",
    "#     if your pyLDAvis call in the cell below is taking too long\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "D_BnRDcsPNyX",
    "outputId": "cb8610bc-200c-4852-cca3-aa476d43875a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el143441403448911538723954009624\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el143441403448911538723954009624_data = {\"mdsDat\": {\"x\": [-0.4566901999339183, 0.058598320385072546, 0.05667266409874955, 0.052979023954740835, 0.05335883666553977, 0.050149935912605234, 0.04866328322127408, 0.04615647977210324, 0.04572200066670668, 0.04438965525712637], \"y\": [0.0015614672833719773, 0.15180851157928538, -0.06779452187622212, -0.02203773789140905, -0.023643710246174777, -0.01336360110286386, -0.010443445093478991, -0.00634648396256316, -0.005762916245663015, -0.003977562444282352], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [91.43221758956706, 2.2469179821550664, 1.7566849595887593, 1.0438800249489621, 1.0363828414585734, 0.7359068239150963, 0.5151087050134535, 0.4851326191501551, 0.4193621337078468, 0.3284063204950304]}, \"tinfo\": {\"Term\": [\"Im\", \"got\", \"like\", \"go\", \"cant\", \"watch\", \"didnt\", \"wish\", \"see\", \"love\", \"long\", \"always\", \"first\", \"thought\", \"also\", \"work\", \"hey\", \"many\", \"hurt\", \"day\", \"cry\", \"feels\", \"bit\", \"might\", \"im\", \"get\", \"files\", \"change\", \"chance\", \"covered\", \"work\", \"day\", \"im\", \"get\", \"sad\", \"today\", \"going\", \"night\", \"dont\", \"want\", \"still\", \"really\", \"one\", \"home\", \"time\", \"good\", \"miss\", \"bed\", \"last\", \"sleep\", \"know\", \"back\", \"tomorrow\", \"morning\", \"amp\", \"feel\", \"need\", \"sick\", \"weekend\", \"tonight\", \"Im\", \"watch\", \"didnt\", \"also\", \"hurt\", \"feels\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"severely\", \"Sod\", \"platform\", \"105\", \"bmore\", \"jeter\", \"tinkissarah\", \"bungalow\", \"rach210\", \"mhmm\", \"coles\", \"deli\", \"shirts\", \"indetad\", \"Frostee\", \"Sweetheart\", \"Dner\", \"quotstuff\", \"morningquot\", \"thwarted\", \"KKNK\", \"LUCK\", \"thereee\", \"dual\", \"castiel\", \"windsor\", \"jaws\", \"Dandy_Sephy\", \"colleague\", \"Rainboot\", \"stuffing\", \"tweeted\", \"EARLY\", \"bits\", \"blizzarding\", \"Colorado\", \"Moo\", \"pugmarks\", \"tore\", \"cutiepie04ct\", \"whore\", \"Castle\", \"Paper\", \"curves\", \"Custardcuppcake\", \"muffs\", \"hungoverrrr\", \"dizzy\", \"spell\", \"Clean\", \"dvds\", \"Food\", \"Another\", \"CRAP\", \"12\", \"white\", \"plane\", \"ahhh\", \"got\", \"like\", \"long\", \"body\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"directors\", \"LettyA\", \"colleague\", \"Rainboot\", \"castiel\", \"windsor\", \"jaws\", \"Dandy_Sephy\", \"stuffing\", \"tweeted\", \"EARLY\", \"bits\", \"WCH\", \"rained\", \"ALREADY\", \"registration\", \"accidentaly\", \"morningstare\", \"1pm\", \"javastix\", \"quotA\", \"Thousand\", \"Splendid\", \"Sunsquot\", \"snowingno\", \"wonderland\", \"castle\", \"60\", \"spell\", \"blizzarding\", \"Colorado\", \"Moo\", \"pugmarks\", \"tore\", \"cutiepie04ct\", \"whore\", \"Castle\", \"Paper\", \"curves\", \"Custardcuppcake\", \"muffs\", \"hungoverrrr\", \"dizzy\", \"todayAarons\", \"dvds\", \"Another\", \"Clean\", \"12\", \"CRAP\", \"white\", \"plane\", \"Food\", \"ahhh\", \"go\", \"cry\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"directors\", \"LettyA\", \"soundtrack\", \"FakerPattyPattz\", \"dvds\", \"bits\", \"EARLY\", \"tweeted\", \"stuffing\", \"castiel\", \"windsor\", \"jaws\", \"Dandy_Sephy\", \"colleague\", \"Rainboot\", \"spell\", \"Another\", \"Clean\", \"12\", \"white\", \"CRAP\", \"blizzarding\", \"Colorado\", \"Moo\", \"plane\", \"Food\", \"pugmarks\", \"ahhh\", \"tore\", \"whore\", \"cutiepie04ct\", \"failed\", \"cant\", \"always\", \"wanted\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"directors\", \"LettyA\", \"soundtrack\", \"dvds\", \"bits\", \"EARLY\", \"tweeted\", \"stuffing\", \"castiel\", \"windsor\", \"jaws\", \"Dandy_Sephy\", \"colleague\", \"Rainboot\", \"spell\", \"Another\", \"Clean\", \"12\", \"CRAP\", \"white\", \"blizzarding\", \"Colorado\", \"Moo\", \"plane\", \"Food\", \"pugmarks\", \"tore\", \"whore\", \"cutiepie04ct\", \"ahhh\", \"see\", \"love\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"directors\", \"LettyA\", \"soundtrack\", \"FakerPattyPattz\", \"dvds\", \"EARLY\", \"bits\", \"tweeted\", \"stuffing\", \"spell\", \"castiel\", \"windsor\", \"jaws\", \"Dandy_Sephy\", \"colleague\", \"Rainboot\", \"Another\", \"Clean\", \"12\", \"white\", \"CRAP\", \"blizzarding\", \"Colorado\", \"Moo\", \"plane\", \"Food\", \"pugmarks\", \"tore\", \"whore\", \"ahhh\", \"cutiepie04ct\", \"failed\", \"wish\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"directors\", \"LettyA\", \"soundtrack\", \"FakerPattyPattz\", \"alydesigns\", \"Another\", \"tweeted\", \"stuffing\", \"spell\", \"dvds\", \"EARLY\", \"bits\", \"12\", \"Clean\", \"castiel\", \"windsor\", \"jaws\", \"Dandy_Sephy\", \"colleague\", \"Rainboot\", \"Awww\", \"upset\", \"cant\", \"update\", \"Facebook\", \"might\", \"cry\", \"result\", \"School\", \"today\", \"also\", \"Blah\", \"thought\", \"many\", \"might\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"directors\", \"LettyA\", \"soundtrack\", \"Awww\", \"upset\", \"cant\", \"update\", \"Facebook\", \"cry\", \"result\", \"School\", \"today\", \"also\", \"Blah\", \"times\", \"ball\", \"save\", \"50\", \"rest\", \"go\", \"whole\", \"body\", \"feels\", \"itchy\", \"first\", \"bit\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"directors\", \"LettyA\", \"soundtrack\", \"FakerPattyPattz\", \"Awww\", \"upset\", \"cant\", \"update\", \"Facebook\", \"might\", \"cry\", \"result\", \"School\", \"today\", \"also\", \"Blah\", \"many\", \"times\", \"ball\", \"save\", \"50\", \"rest\", \"go\", \"whole\", \"body\", \"feels\", \"hey\", \"switchfoot\", \"texting\", \"Kenichan\", \"dived\", \"Managed\", \"bounds\", \"nationwideclass\", \"Kwesidei\", \"LOLTrish\", \"Rains\", \"Tatiana_K\", \"twittera\", \"muera\", \"repierced\", \"caregiving\", \"UA\", \"octolinz16\", \"counts\", \"smarrison\", \"wouldve\", \"iamjazzyfizzle\", \"iamlilnicki\", \"Hollis\", \"wry\", \"directors\", \"LettyA\", \"soundtrack\", \"FakerPattyPattz\", \"alydesigns\", \"Awww\", \"upset\", \"cant\", \"update\", \"Facebook\", \"might\", \"cry\", \"result\", \"School\", \"today\", \"also\", \"Blah\", \"many\", \"times\", \"ball\", \"save\", \"50\", \"rest\", \"go\", \"whole\", \"body\", \"feels\", \"itchy\"], \"Freq\": [382.0, 152.0, 147.0, 128.0, 119.0, 66.0, 66.0, 36.0, 35.0, 30.0, 30.0, 15.0, 9.0, 9.0, 13.0, 948.0, 6.0, 5.0, 8.0, 821.0, 6.0, 7.0, 4.0, 4.0, 678.0, 663.0, 29.0, 29.0, 29.0, 29.0, 948.0267130694998, 821.2577019905838, 678.3015402426028, 663.059912634169, 563.0457306867135, 558.0684415442056, 551.542186877033, 522.2157720736196, 481.9618741122875, 449.39672318882447, 430.0085069690979, 417.5304669587472, 411.2123744255485, 405.21040738432924, 374.6793574610715, 366.93104537867134, 363.08785163721944, 327.7780169920814, 315.5648233082432, 307.81371268390745, 305.1275514127091, 295.27857693073355, 287.3348058998122, 283.7917420626097, 283.28010274873793, 277.60150448450776, 268.3651637562561, 267.9160526489648, 264.984497661375, 263.10357567711486, 382.1805059628763, 65.91451421540792, 65.76458844837545, 13.357227484670867, 8.004632175369236, 7.1175491369124435, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.05071875623118879, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.050718761498750646, 0.05376009895677583, 0.05376009895677583, 0.05376009895677583, 0.05376009895677583, 0.05376009368921397, 0.05376009368921397, 0.05376009895677583, 0.053760035746033524, 0.05376116300427133, 0.05376268006208668, 0.052463351648603426, 0.052463351648603426, 0.052463351648603426, 0.052185371874186454, 0.05212004357201258, 0.05212004357201258, 0.05212004357201258, 0.051931823051670975, 0.051931823051670975, 0.051931823051670975, 0.051931823051670975, 0.051931823051670975, 0.051931823051670975, 0.051931823051670975, 0.05374716709241227, 0.05310316551466895, 0.053893073288341475, 0.052220359020053154, 0.05346028513845378, 0.05290567935301756, 0.05290270844812915, 0.05269616208008048, 0.05242906508846396, 0.05223187391027667, 152.30525858517922, 146.93303190944633, 30.44730516132312, 4.559544910110506, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04471337638922083, 0.04555979497379188, 0.04555979497379188, 0.04555979497379188, 0.04555979497379188, 0.04555979497379188, 0.04555979497379188, 0.04555979497379188, 0.04555977850065532, 0.04556000500628306, 0.04556035506043501, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.044713380507504966, 0.04555617912031641, 0.04521558054874983, 0.04521558054874983, 0.04521558054874983, 0.04512907187209178, 0.045112092186579966, 0.045112092186579966, 0.045112092186579966, 0.04506060539825382, 0.04506060539825382, 0.04506060539825382, 0.04506060539825382, 0.04506060539825382, 0.04506060539825382, 0.04506060539825382, 0.04506060539825382, 0.04558608609974566, 0.04547642442964899, 0.04535072616110871, 0.045321342203765325, 0.04528295155900638, 0.04527775428442091, 0.04517092599381299, 0.04513652184810218, 0.04511861966694286, 127.90299290693532, 6.211437459259436, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030193812488373557, 0.030208065097602706, 0.030207761642323788, 0.0302077591951038, 0.030207754300663813, 0.030207754300663813, 0.030207754300663813, 0.030207754300663813, 0.030207754300663813, 0.030207754300663813, 0.030207754300663813, 0.030207754300663813, 0.030207695567384025, 0.030206381410248714, 0.030204516628615365, 0.03020382895979782, 0.030203080110480493, 0.030202911252301092, 0.030201893208784726, 0.030201893208784726, 0.030201893208784726, 0.03020107583730764, 0.03020072588484889, 0.030200630443269233, 0.03020037348517015, 0.03020031964633034, 0.03020031964633034, 0.03020031964633034, 0.03020026091305055, 119.64151703167941, 15.257948924686675, 3.9093206281247173, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029661450745816578, 0.029674670438658415, 0.02967436430351817, 0.02967435944423023, 0.02967435701458626, 0.02967435701458626, 0.02967435701458626, 0.02967435701458626, 0.02967435701458626, 0.02967435701458626, 0.02967435701458626, 0.02967435701458626, 0.029674301132774947, 0.029673086310789847, 0.02967150947185319, 0.029670724696850816, 0.029669986085083876, 0.029669976366507998, 0.02966889760458523, 0.02966889760458523, 0.02966889760458523, 0.029668178429970053, 0.029667942754504944, 0.029667850428034076, 0.029667566159689563, 0.029667566159689563, 0.029667566159689563, 0.02966755644111368, 35.19779219262623, 30.196619083441433, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920397485288582, 0.022920652818301503, 0.02292064764263232, 0.02292064764263232, 0.022920645917409263, 0.022920645917409263, 0.022920645917409263, 0.022920645917409263, 0.022920645917409263, 0.022920645917409263, 0.022920645917409263, 0.022920645917409263, 0.022920645917409263, 0.022920621764286418, 0.022920594160717456, 0.022920576908486853, 0.022920559656256247, 0.022920559656256247, 0.022920540678802587, 0.022920540678802587, 0.022920540678802587, 0.022920526877018104, 0.022920521701348923, 0.022920519976125864, 0.022920514800456683, 0.022920514800456683, 0.022920514800456683, 0.022920514800456683, 0.022920511350010563, 35.86621235976976, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597991433657013, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 0.016597990226061992, 9.33313123576062, 5.390077660197738, 3.85134237256179, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 0.01648630354341138, 9.424010076006907, 4.466076801879143, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 0.014371869381937422, 5.707890899761935, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583, 0.011543916474577583], \"Total\": [382.0, 152.0, 147.0, 128.0, 119.0, 66.0, 66.0, 36.0, 35.0, 30.0, 30.0, 15.0, 9.0, 9.0, 13.0, 948.0, 6.0, 5.0, 8.0, 821.0, 6.0, 7.0, 4.0, 4.0, 678.0, 663.0, 29.0, 29.0, 29.0, 29.0, 948.2639212995032, 821.4949102656967, 678.5387484185017, 663.2971207901469, 563.2829389167168, 558.3056498591604, 551.7793950871154, 522.452980283702, 482.1990822735327, 449.63393138952097, 430.2457152336755, 417.76767511472485, 411.4495826144295, 405.4476155350394, 374.91656564223774, 367.1682536192098, 363.3250597879296, 328.0152251281382, 315.802031696465, 308.0509209390993, 305.3647596004409, 295.5157850814437, 287.572013976106, 284.0289503471084, 283.51731095882025, 277.83871265513886, 268.60237190696625, 268.15326085377956, 265.22170593648775, 263.3407838701142, 382.5145516772084, 66.24856502436624, 66.09861859768768, 13.691296042330634, 8.338689905322806, 7.451594257666249, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.38472317452895843, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139935840359, 0.8876139935840359, 0.887617749960963, 0.8892587806243863, 0.8933601059737908, 0.9036746374337986, 0.6844278472066394, 0.6844278472066394, 0.6844278472066394, 0.6402976657490931, 0.6306299764576129, 0.6306299764576129, 0.630636701660832, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 1.2425904304716826, 1.1280434372230383, 2.110292161237801, 0.8300179507507592, 8.89250729684545, 65.15720385458228, 24.106386150309394, 2.8515313093134114, 17.885133032659663, 5.3452519734962465, 152.6453050548956, 147.27307778970268, 30.787360924267972, 4.899618866974161, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.8876139935840359, 0.8876139935840359, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.887617749960963, 0.8892587806243863, 0.8933601059737908, 0.9036746374337986, 0.3847239958532114, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 0.3847240360436689, 1.2425904304716826, 0.6844278472066394, 0.6844278472066394, 0.6844278472066394, 0.6402976657490931, 0.6306299764576129, 0.6306299764576129, 0.630636701660832, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 0.5885250172756454, 2.110292161237801, 8.89250729684545, 1.1280434372230383, 24.106386150309394, 65.15720385458228, 2.8515313093134114, 17.885133032659663, 0.8300179507507592, 5.3452519734962465, 128.2575553960693, 6.565985778010169, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 2.110292161237801, 0.9036746374337986, 0.8933601059737908, 0.8892587806243863, 0.887617749960963, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139935840359, 0.8876139935840359, 1.2425904304716826, 8.89250729684545, 1.1280434372230383, 24.106386150309394, 2.8515313093134114, 65.15720385458228, 0.6844278472066394, 0.6844278472066394, 0.6844278472066394, 17.885133032659663, 0.8300179507507592, 0.6402976657490931, 5.3452519734962465, 0.6306299764576129, 0.630636701660832, 0.6306299764576129, 4.254846464311078, 119.99662088170106, 15.613041604021925, 4.264397017973421, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 2.110292161237801, 0.9036746374337986, 0.8933601059737908, 0.8892587806243863, 0.887617749960963, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139935840359, 0.8876139935840359, 1.2425904304716826, 8.89250729684545, 1.1280434372230383, 24.106386150309394, 65.15720385458228, 2.8515313093134114, 0.6844278472066394, 0.6844278472066394, 0.6844278472066394, 17.885133032659663, 0.8300179507507592, 0.6402976657490931, 0.6306299764576129, 0.630636701660832, 0.6306299764576129, 5.3452519734962465, 35.55962867282653, 30.5584499024033, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 2.110292161237801, 0.8933601059737908, 0.9036746374337986, 0.8892587806243863, 0.887617749960963, 1.2425904304716826, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139935840359, 0.8876139935840359, 8.89250729684545, 1.1280434372230383, 24.106386150309394, 2.8515313093134114, 65.15720385458228, 0.6844278472066394, 0.6844278472066394, 0.6844278472066394, 17.885133032659663, 0.8300179507507592, 0.6402976657490931, 0.6306299764576129, 0.630636701660832, 5.3452519734962465, 0.6306299764576129, 4.254846464311078, 36.23437860825864, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 8.89250729684545, 0.8892587806243863, 0.887617749960963, 1.2425904304716826, 2.110292161237801, 0.8933601059737908, 0.9036746374337986, 24.106386150309394, 1.1280434372230383, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139988515979, 0.8876139935840359, 0.8876139935840359, 10.542307494010743, 65.88187266114004, 119.99662088170106, 21.182223670209268, 0.5582640073449069, 4.219600237830587, 6.565985778010169, 0.41017028641809306, 32.27966787258823, 558.3056498591604, 13.691296042330634, 0.38651087245917903, 9.701404067092561, 5.758337330026149, 4.219600237830587, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 10.542307494010743, 65.88187266114004, 119.99662088170106, 21.182223670209268, 0.5582640073449069, 6.565985778010169, 0.41017028641809306, 32.27966787258823, 558.3056498591604, 13.691296042330634, 0.38651087245917903, 21.482625630433184, 0.38938154579466355, 0.8083619474903889, 0.623885973986759, 22.865067447151862, 128.2575553960693, 14.904790212763224, 4.899618866974161, 7.451594257666249, 0.3852042138270382, 9.79441129016379, 4.836475762964541, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 10.542307494010743, 65.88187266114004, 119.99662088170106, 21.182223670209268, 0.5582640073449069, 4.219600237830587, 6.565985778010169, 0.41017028641809306, 32.27966787258823, 558.3056498591604, 13.691296042330634, 0.38651087245917903, 5.758337330026149, 21.482625630433184, 0.38938154579466355, 0.8083619474903889, 0.623885973986759, 22.865067447151862, 128.2575553960693, 14.904790212763224, 4.899618866974161, 7.451594257666249, 6.081151763321625, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 0.38472280754727917, 10.542307494010743, 65.88187266114004, 119.99662088170106, 21.182223670209268, 0.5582640073449069, 4.219600237830587, 6.565985778010169, 0.41017028641809306, 32.27966787258823, 558.3056498591604, 13.691296042330634, 0.38651087245917903, 5.758337330026149, 21.482625630433184, 0.38938154579466355, 0.8083619474903889, 0.623885973986759, 22.865067447151862, 128.2575553960693, 14.904790212763224, 4.899618866974161, 7.451594257666249, 0.3852042138270382], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.1296, -4.2731, -4.4643, -4.4871, -4.6506, -4.6595, -4.6712, -4.7259, -4.8061, -4.876, -4.9201, -4.9496, -4.9648, -4.9795, -5.0579, -5.0788, -5.0893, -5.1916, -5.2296, -5.2544, -5.2632, -5.296, -5.3233, -5.3357, -5.3375, -5.3577, -5.3916, -5.3933, -5.4043, -5.4114, -1.332, -3.0895, -3.0918, -4.6858, -5.1979, -5.3153, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2594, -10.2011, -10.2011, -10.2011, -10.2011, -10.2011, -10.2011, -10.2011, -10.2011, -10.2011, -10.2011, -10.2255, -10.2255, -10.2255, -10.2308, -10.2321, -10.2321, -10.2321, -10.2357, -10.2357, -10.2357, -10.2357, -10.2357, -10.2357, -10.2357, -10.2014, -10.2134, -10.1986, -10.2302, -10.2067, -10.2171, -10.2172, -10.2211, -10.2262, -10.23, -2.0059, -2.0418, -3.6158, -5.5145, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1205, -10.1205, -10.1205, -10.1205, -10.1205, -10.1205, -10.1205, -10.1205, -10.1205, -10.1205, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1392, -10.1206, -10.1281, -10.1281, -10.1281, -10.13, -10.1304, -10.1304, -10.1304, -10.1315, -10.1315, -10.1315, -10.1315, -10.1315, -10.1315, -10.1315, -10.1315, -10.1199, -10.1223, -10.1251, -10.1257, -10.1266, -10.1267, -10.1291, -10.1298, -10.1302, -1.66, -4.6849, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0114, -10.0109, -10.0109, -10.0109, -10.0109, -10.0109, -10.0109, -10.0109, -10.0109, -10.0109, -10.0109, -10.0109, -10.0109, -10.011, -10.011, -10.0111, -10.0111, -10.0111, -10.0111, -10.0111, -10.0111, -10.0112, -10.0112, -10.0112, -10.0112, -10.0112, -10.0112, -10.0112, -10.0112, -1.7196, -3.779, -5.1407, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.022, -10.0215, -10.0215, -10.0215, -10.0215, -10.0215, -10.0215, -10.0215, -10.0215, -10.0215, -10.0215, -10.0215, -10.0215, -10.0216, -10.0216, -10.0217, -10.0217, -10.0217, -10.0217, -10.0217, -10.0217, -10.0218, -10.0218, -10.0218, -10.0218, -10.0218, -10.0218, -10.0218, -2.6007, -2.754, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -9.9374, -2.2252, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -9.9034, -3.5114, -4.0604, -4.3966, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -9.8502, -3.3561, -4.1028, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -9.8418, -3.613, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164, -9.8164], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0893, 0.0893, 0.0892, 0.0892, 0.0892, 0.0891, 0.0891, 0.0891, 0.0891, 0.089, 0.089, 0.089, 0.089, 0.089, 0.0889, 0.0889, 0.0889, 0.0888, 0.0888, 0.0888, 0.0888, 0.0888, 0.0887, 0.0887, 0.0887, 0.0887, 0.0887, 0.0887, 0.0887, 0.0887, 3.7947, 3.7906, 3.7905, 3.7709, 3.7547, 3.7497, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 1.7694, 0.9916, 0.9916, 0.9916, 0.9916, 0.9916, 0.9916, 0.9916, 0.9898, 0.9852, 0.9737, 1.2271, 1.2271, 1.2271, 1.2885, 1.3024, 1.3024, 1.3024, 1.3679, 1.3679, 1.3679, 1.3679, 1.3679, 1.3679, 1.3679, 0.6549, 0.7396, 0.128, 1.0296, -1.3184, -3.3204, -2.3262, -0.1955, -2.0367, -0.8327, 4.0395, 4.0394, 4.0306, 3.9698, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.0722, 1.0722, 1.0722, 1.0722, 1.0722, 1.0722, 1.0722, 1.0704, 1.0658, 1.0543, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 1.8895, 0.7357, 1.3246, 1.3246, 1.3246, 1.3893, 1.4042, 1.4042, 1.4042, 1.4721, 1.4721, 1.4721, 1.4721, 1.4721, 1.4721, 1.4721, 1.4721, 0.2068, -1.234, 0.8279, -2.2347, -3.2299, -0.1011, -1.9395, 1.13, -0.7329, 4.5595, 4.5067, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 2.0173, 0.3158, 1.1639, 1.1753, 1.1799, 1.1818, 1.1818, 1.1818, 1.1818, 1.1818, 1.1818, 1.1818, 0.8454, -1.1227, 0.942, -2.12, 0.0146, -3.1144, 1.4415, 1.4415, 1.4415, -1.8216, 1.2486, 1.5082, -0.6139, 1.5234, 1.5233, 1.5234, -0.3857, 4.5665, 4.5464, 4.4825, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 2.0068, 0.3051, 1.1532, 1.1647, 1.1693, 1.1712, 1.1712, 1.1712, 1.1712, 1.1712, 1.1712, 1.1712, 0.8348, -1.1333, 0.9314, -2.1306, -3.125, 0.004, 1.4309, 1.4309, 1.4309, -1.8322, 1.2381, 1.4976, 1.5128, 1.5128, 1.5128, -0.6245, 4.9016, 4.8999, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 2.0913, 0.3893, 1.2489, 1.2374, 1.2535, 1.2553, 0.9189, 1.2553, 1.2553, 1.2553, 1.2553, 1.2553, 1.2553, -1.0491, 1.0156, -2.0464, 0.0882, -3.0407, 1.5153, 1.5153, 1.5153, -1.7479, 1.3224, 1.5819, 1.5971, 1.5971, -0.5401, 1.5971, -0.312, 5.2583, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, 2.1253, -1.0151, 1.2874, 1.2893, 0.9529, 0.4232, 1.2828, 1.2714, -2.0124, 1.0496, 1.2893, 1.2893, 1.2893, 1.2893, 1.2893, 1.2893, -1.1853, -3.0178, -3.6174, -1.8831, 1.753, -0.2697, -0.7118, 2.0613, -2.3044, -5.1548, -1.4467, 2.1207, 5.2898, 5.2624, 5.2372, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, 2.1785, -1.1321, -2.9646, -3.5642, -1.8299, 1.8062, -0.6586, 2.1145, -2.2512, -5.1016, -1.3935, 2.1739, -1.844, 2.1665, 1.436, 1.6951, -1.9063, -3.6308, -1.4784, -0.3659, -0.7852, 2.1773, 5.4356, 5.3945, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, 2.1869, -1.1237, -2.9562, -3.5558, -1.8215, 1.8146, -0.208, -0.6502, 2.1229, -2.2427, -5.0932, -1.3851, 2.1823, -0.5189, -1.8355, 2.1749, 1.4445, 1.7035, -1.8979, -3.6223, -1.47, -0.3574, -0.7767, 5.6553, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, 2.2123, -1.0983, -2.9308, -3.5304, -1.7961, 1.84, -0.1827, -0.6248, 2.1483, -2.2174, -5.0678, -1.3597, 2.2077, -0.4936, -1.8102, 2.2003, 1.4698, 1.7289, -1.8725, -3.597, -1.4446, -0.3321, -0.7514, 2.2111]}, \"token.table\": {\"Topic\": [1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 5, 1, 1, 1, 9, 1, 3, 5, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 2, 1, 9, 1, 4, 1, 1, 3, 10, 1, 2, 1, 1, 1, 1, 3, 3, 6, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 2, 1, 1, 1, 1, 7, 1], \"Freq\": [0.9955868063489048, 1.0120880084284758, 0.948558937944199, 0.9975873142909397, 0.8864906855552926, 1.126615850238739, 1.119369438273683, 1.204793220550821, 0.998654818032537, 1.1266158569246618, 0.9913360981998913, 0.9354095980492343, 0.9495083562437558, 0.9607352865911787, 0.998175381400625, 0.9982546276460272, 0.9999535840809455, 0.8270484948213987, 1.1065929689470322, 1.0204875390823676, 1.0000281601121275, 1.126615850238739, 0.9946833687060004, 0.9947666736998915, 1.1266158569246618, 0.9987967052093352, 0.9138003344591935, 0.9993975492002298, 0.9985080081886746, 0.9995871367639397, 0.9477360702637928, 0.940104427633597, 1.0005805070982363, 0.9393962899681976, 0.9996219974627171, 0.9188913691054008, 0.9995520547567085, 0.9979918890916488, 1.0003998063625588, 0.999541753358164, 0.9957725194714405, 0.9866551984755436, 0.9988959966272123, 0.9593833193021591, 0.9992060167237946, 1.126615850238739, 0.9988054954313714, 1.0006268746989104, 0.9981457725077721, 0.9744258390251521, 0.9817251888041815, 0.8683061990703651, 0.9479570989067226, 0.9991053196602532, 0.9998980725483335, 0.9977573842602742, 0.9991329740650421, 0.9989073202807187, 1.006422483250786, 1.0005561102476666, 1.0059012532178184, 0.9994976966331326, 1.2370696110876613, 0.9842622464375119, 0.9994284579896899, 0.9998346996043899, 0.8047704017971584, 0.9994288955706576, 1.1266110891135057, 0.9277007676165409, 1.000222541134237, 0.9775341413691315, 0.9994525402720937, 0.9980108844104922, 0.9987059206511579, 1.1245320504992455, 0.9913973304669826, 1.0017930173215863, 0.9985901166587631, 0.9379989675306849, 0.9962479938354163, 0.9991640731828305, 1.0520663021309546, 1.0063878649667437, 1.126615850238739, 0.9935315957590282, 0.9997216794886159], \"Term\": [\"12\", \"Another\", \"Awww\", \"CRAP\", \"Clean\", \"Dandy_Sephy\", \"EARLY\", \"Food\", \"Im\", \"Rainboot\", \"School\", \"ahhh\", \"also\", \"always\", \"amp\", \"back\", \"bed\", \"bit\", \"bits\", \"body\", \"cant\", \"castiel\", \"chance\", \"change\", \"colleague\", \"covered\", \"cry\", \"day\", \"didnt\", \"dont\", \"dvds\", \"failed\", \"feel\", \"feels\", \"files\", \"first\", \"get\", \"go\", \"going\", \"good\", \"got\", \"hey\", \"home\", \"hurt\", \"im\", \"jaws\", \"know\", \"last\", \"like\", \"long\", \"love\", \"many\", \"might\", \"miss\", \"morning\", \"need\", \"night\", \"one\", \"plane\", \"really\", \"rest\", \"sad\", \"save\", \"see\", \"sick\", \"sleep\", \"spell\", \"still\", \"stuffing\", \"thought\", \"time\", \"times\", \"today\", \"tomorrow\", \"tonight\", \"tweeted\", \"update\", \"upset\", \"want\", \"wanted\", \"watch\", \"weekend\", \"white\", \"whole\", \"windsor\", \"wish\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 1, 6, 10, 9, 2, 4, 7, 3, 8]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el143441403448911538723954009624\", ldavis_el143441403448911538723954009624_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el143441403448911538723954009624\", ldavis_el143441403448911538723954009624_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el143441403448911538723954009624\", ldavis_el143441403448911538723954009624_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukn2e3iWRoIz"
   },
   "source": [
    "# 2.word2Vec [40pts]\n",
    "\n",
    "\n",
    "In this problem, we use Amazon Review Dataset to perform Word2Vec and Doc2Vec to extract insights relevant for e-commerce business. For this question, download and use the dataset [here](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz||reviews_Electronics_5.json.gz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UKcbiFCRuJr"
   },
   "source": [
    "## 2.1 Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcw3Abp6R549"
   },
   "source": [
    "The following code reads the data from a GZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T-HJ5AnnRpFB"
   },
   "outputs": [],
   "source": [
    "# A function to read the zipped data at a specfic path\n",
    "#\n",
    "# How to use:\n",
    "# PATH = \"/path/to/file\"\n",
    "# for line in parse(PATH):\n",
    "#   do something with line\n",
    "#\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O543cF24R81Z"
   },
   "source": [
    "We will now read the data and preprocess it using the following steps:\n",
    "\n",
    "   1. Remove stopwords\n",
    "   2. Lower-case all words\n",
    "   3. Remove words with less than 2 characters\n",
    "   4. Remove punctuation\n",
    "   5. Split each sentence into a list of words\n",
    "\n",
    "   And finally extract 10000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4_GNZ3ikR_rE"
   },
   "outputs": [],
   "source": [
    "# A function to clean a single line of text\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "\n",
    "def clean_line(line):\n",
    "    \"\"\" Clean stopwords and punction for each line\n",
    "    \n",
    "    Args: \n",
    "        line (string): one line in file\n",
    "        \n",
    "    Returns:\n",
    "        list(str): a list of all words in the sentence\n",
    "    \"\"\"\n",
    "    line = line.split(\" \")\n",
    "    filtered_content = []\n",
    "    stop_words = STOPWORDS\n",
    "    punctuationRegex = r'\\W+|\\d+' # Regular expression to match punctuation and digits\n",
    "\n",
    "\n",
    "    for word in line:\n",
    "      word = word.lower()\n",
    "      word = re.sub(punctuationRegex, '', word) # Remove punctuation and digits\n",
    "      if word not in stop_words and word != '' and len(word) >= 2:\n",
    "        filtered_content.append(word)\n",
    "\n",
    "        \n",
    "    return filtered_content\n",
    "\n",
    "def read_dataset(fname):\n",
    "    \"\"\" Read the 100000 lines in given dataset into list and clean stop words. \n",
    "        \n",
    "    Args: \n",
    "        fname (string): filename of Amazon Review Dataset\n",
    "        \n",
    "    Returns:\n",
    "        list of list of words: we view each document as a list, including a list of all words \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    exp_dataset = []\n",
    "    #print('123')\n",
    "    for review in parse(fname):\n",
    "        # if(count == 0):\n",
    "        #   print('review:', review, '\\n')\n",
    "        line = review[\"reviewText\"]\n",
    "        # if(count == 0):\n",
    "        #   print('line', line, '\\n')\n",
    "        new_line = clean_line(line)\n",
    "        # if(count == 0):\n",
    "        #   print('new line', new_line, '\\n')\n",
    "        exp_dataset.append(new_line)\n",
    "        count += 1\n",
    "        if count > 100000:\n",
    "            break\n",
    "    return exp_dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "zaf3YFgHTNr3",
    "outputId": "cc784330-536f-4dfc-dfeb-8379f3536788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 251 ms, total: 15.1 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r = read_dataset(\"reviews_Electronics_5.json.gz\")\n",
    "\n",
    "#Desktop/22_courses/BA820_Unsupervised_and_Unstructured_Machine_Learning/HW3/reviews_Electronics_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JamafEPNS3Ii"
   },
   "source": [
    "## 2.2 Build a doc2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFMVOQgrTi9s"
   },
   "source": [
    "**[3pts]2.2.1** In this question, first we will build a Word2Vec model using ginsim using size=300, min_count=40, win- dow=10, negative=10, max_vocab_size=10000. Train the model for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5gGK2QnKTfdO"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# YOUR CODE HERE\n",
    "model = Word2Vec(r, vector_size= 300, min_count= 40, window= 10, negative= 10, max_vocab_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPnJE0pQT6jr"
   },
   "source": [
    "**[2pts]2.2.2** Use model.wv.doesnt_match to find a word in [\"Canon\",\"Nikon\",\"junk\"] that does not\n",
    "\n",
    "belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pGQT-f_OTqnX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'junk'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE [\"Canon\", \"Nikon\", \"junk\"]\n",
    "model.wv.doesnt_match(['canon', 'nikon', 'junk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a44R5v_-UFXp"
   },
   "source": [
    "**[3pts]2.2.3** Come up with 3 other word lists and apply the above function. Explain your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GP9dTi1yUNGR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functionality, software, route, who doesn't belong:  route\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "print(\"functionality, software, route, who doesn't belong: \", \n",
    "      model.wv.doesnt_match(['functionality', 'software', 'route']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlZKiD_DUN00"
   },
   "source": [
    "In the three words of the list, `functionality, software, and route`, software and functionality is close to each other since when reviewing a software, we often evaluate its functionality. Therefore, the word route is the one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kWcOMa3LulWL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive, better, truck, who doesn't belong:  better\n"
     ]
    }
   ],
   "source": [
    "print(\"drive, better, truck, who doesn't belong: \", model.wv.doesnt_match(['drive', 'better', 'truck']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QM5RBiwulxi"
   },
   "source": [
    "In the three words of the list, `drive, better, and truck`, drive and truck is closer to each other since when talking about truck, we are likely to mentioned the driving experience. While better can be used to review truck, it's more general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xJiEafi2usBk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive, better, truck, who doesn't belong:  room\n"
     ]
    }
   ],
   "source": [
    "print(\"drive, better, truck, who doesn't belong: \", model.wv.doesnt_match(['tv', 'hdmi', 'room']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eBm1u4mustG"
   },
   "source": [
    "In the three words of the list, `TV, HDMI, and room`, TV and HDMI is closer to each other since almost every TV nowadays includes a HDMI port, and it's a key thing to look at when reviewing. While room is more general and can appear in many other review as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLz_WXiHUG4L"
   },
   "source": [
    "**[2pts]2.2.4** What are some tasks in e-commerce that can be solved with this simple function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjaKCXMEUYyM"
   },
   "source": [
    "- Using the function to check whithin the 3 product, which one is more relevant. We can use the relevant products pair to recommend.\n",
    "- Feeding the function a list of a product and serveral features. See which feature is less relevant. By doing so, we get to know what people are looking for when purchasing the product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZmhD59iUtR3"
   },
   "source": [
    "## 2.3 Build a doc2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRC20sS1VYJN"
   },
   "source": [
    "**[15 pts] 2.3.1**  Each review is marked by other customers as “helpful” or not. The \"helpful: [a, b]\" item in each review is (a) the number of people who marked the review as helpful, and (b) the total number of people who have marked the review as helpful or unhelpful. The \"helpfulness\" score of a review can be calculated as a/b. Define a \"helpful\" review as one with helpfulness score >= 0.8. Given a review that is only slightly helpful, could we find textually similar reviews but have higher helpfulness? Build Doc2Vec model with gensim on review data. Use product ID “B00006I5WJ” and ReviewerID with “A14453U0KFWF31” as an example, find top 5 helpful reviews of the same product with similarity score above 0.8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xGDDL9a4UBGi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def read_reviewers_data(fname, min_count=0):\n",
    "    '''\n",
    "    Save all reviews into their own product asin files.\n",
    "    Make sure you have 'product' folder when you run this answer.\n",
    "    In each file, you can choose your own log structure. In this answer, log strucutre is like \n",
    "        \"reviewText\"\\t\"reviewerID\"\\t\"helpful\"\n",
    "    Args: \n",
    "        fname: dataset file path\n",
    "        min_count: minimum number of reviews of a product\n",
    "    Returns:\n",
    "        none\n",
    "    '''\n",
    "    if not os.path.isdir('product'):\n",
    "        os.makedirs('product')\n",
    "    asin_list = []\n",
    "    tmp_list = []\n",
    "    last_asin = \"\"\n",
    "    j = 0\n",
    "    for i in parse(fname):\n",
    "        if last_asin != i['asin']:\n",
    "            if len(tmp_list) > min_count:\n",
    "                f = open(\"product/\" + last_asin+\".txt\", 'w')\n",
    "                for one in tmp_list:\n",
    "                    f.write(one)\n",
    "                f.close()\n",
    "            tmp_list = []\n",
    "            last_asin = i['asin']\n",
    "        tmp_list.append(i[\"reviewText\"] + '\\t' + i[\"reviewerID\"] +\n",
    "                    '\\t' + handle_helpful(i[\"helpful\"]) + \"\\n\")\n",
    "        j += 1\n",
    "        if j > 100000:\n",
    "            break\n",
    "            \n",
    "def handle_helpful(helpful):\n",
    "    '''\n",
    "    Helper function for helpful_score calculate\n",
    "    Args: \n",
    "        helpful: list. The first element is the number of people think this is helpful. The second element\n",
    "            is the total number of people evaluate this comment\n",
    "    Returns:\n",
    "        String: number represent helpfulness\n",
    "    '''\n",
    "    if helpful[1] != 0:\n",
    "        helpfulness = 1.0 * helpful[0] / helpful[1]\n",
    "        return str(helpfulness)\n",
    "    else:\n",
    "        return str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZcaWNGSyban3"
   },
   "outputs": [],
   "source": [
    "read_reviewers_data(\"reviews_Electronics_5.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "phyr9d9Zbvbe"
   },
   "outputs": [],
   "source": [
    "class TaggedReviewDocument(object):\n",
    "    '''\n",
    "    This class could save all products and review information in its dictionary and generate iter for TaggedDocument\n",
    "        which could used for Doc2Vec model\n",
    "    '''\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "        self.helpfulness = {}  # key:reviewerID value:helpfulness\n",
    "        self.product = {}      # key:asin value:reviewerID\n",
    "        self.asin = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        for filename in os.listdir(self.dirname):\n",
    "            asin_code = filename[:-4] #delete \".txt\"\n",
    "            self.product[asin_code] = []\n",
    "            self.asin.append(asin_code)\n",
    "            for line in enumerate(open(self.dirname + \"/\" + filename)):\n",
    "                line_content = line[1].split(\"\\t\")\n",
    "                self.product[asin_code].append(line_content[1])\n",
    "                self.helpfulness[line_content[1]] = float(line_content[2])\n",
    "                yield TaggedDocument(clean_line(line_content[0]), [line_content[1], line_content[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "59Ccalf7bwE2"
   },
   "outputs": [],
   "source": [
    "documents = TaggedReviewDocument(\"product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "crSL0O9HbyPI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 2s, sys: 9.66 s, total: 4min 12s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "# YOUR CODE HERE\n",
    "model = Doc2Vec(vector_size=5, min_count=10, epochs=10)\n",
    "model.build_vocab(documents)\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbabO2WUcZxJ"
   },
   "source": [
    "## Find similar reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "yCI8l3_9b0ru"
   },
   "outputs": [],
   "source": [
    "def find_similar_reviews(asin,reviewer_id):\n",
    "    '''\n",
    "    If one review is similar to the specefic review and it is much helpful, save it to a list\n",
    "    Args: \n",
    "        asin: product asin\n",
    "        reviewer_id: the specific review\n",
    "    Returns:\n",
    "        list of reviewer id\n",
    "    '''\n",
    "    result = []\n",
    "    ########################\n",
    "    reviews_for_asin = documents.product[asin]\n",
    "    similar_reviews = []\n",
    "    reviews_similarity = model.dv.most_similar(reviewer_id, topn=len(model.dv))\n",
    "    for rev in reviews_similarity:\n",
    "        # filter for similarity score > xx & is for the same product\n",
    "        if (rev[0] in reviews_for_asin) & (rev[1] > 0.8) & (rev[0] != reviewer_id):\n",
    "            similar_reviews.append(rev)\n",
    "    \n",
    "    # filter for helpful reviews only and build a dictionary\n",
    "    helpful_reviews = {} # reviewer_id: helpfulness score\n",
    "    for rev in similar_reviews: \n",
    "        if documents.helpfulness[rev[0]] >= 0.8:\n",
    "            helpful_reviews.update({rev[0]: documents.helpfulness[rev[0]]})\n",
    "    \n",
    "    # Review with top 5 helpfulness\n",
    "    result = dict(sorted(helpful_reviews.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "\n",
    "    ########################\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TU-cVz3cc6gO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A1ZJSYEQQDIDAA': 1.0, 'A3GTQ229J3PFN8': 1.0, 'A1XX32LG8E078Y': 1.0, 'A3I4TQNEO4G6LT': 1.0, 'A2A0HREDAG2QIC': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(find_similar_reviews(\"B00006I5WJ\", \"A14453U0KFWF31\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KIVR0OodJbc"
   },
   "source": [
    "## 2.4 Build a doc2vec model using product descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aP5_XP5dO2i"
   },
   "source": [
    "**[10pts]2.4.1** Use product descriptions (located in meta data  [here](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Electronics.json.gz)) to build a Doc2Vec model. When building the doc2vec model, use vector_size=100, window=15, min_count=5, max_vocab_size=1000, and train it for 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6j9r0LvidJ7V"
   },
   "outputs": [],
   "source": [
    "def read_product_description(fname):\n",
    "    '''\n",
    "    Load all product descriptions\n",
    "    Args: \n",
    "        fname: dataset file path\n",
    "    Returns:\n",
    "        dict: key is asin, value is description content\n",
    "    '''\n",
    "    result = {}\n",
    "    for i in parse(fname):\n",
    "        try:\n",
    "            if \"Camera & Photo\" in i[\"categories\"][0]:\n",
    "                result[i[\"asin\"]]=i[\"description\"]\n",
    "        except:\n",
    "            continue\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "XrSISgv3df6_"
   },
   "outputs": [],
   "source": [
    "class TaggedDescriptionDocument(object):\n",
    "    '''\n",
    "    This class could save all products and review information in its dictionary and generate iter for TaggedDocument\n",
    "        which could used for Doc2Vec model\n",
    "    '''\n",
    "    def __init__(self, descriptondict):\n",
    "        self.descriptondict = descriptondict\n",
    "        \n",
    "\n",
    "    def __iter__(self):\n",
    "        for asin in self.descriptondict:\n",
    "            for content in self.descriptondict[asin]:\n",
    "                yield TaggedDocument(clean_line(content), [asin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yTRwOCtldinm"
   },
   "outputs": [],
   "source": [
    "description_dict = read_product_description(\"meta_Electronics.json.gz\")\n",
    "des_documents = TaggedDescriptionDocument(description_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "0eG6BC6oeNUA"
   },
   "outputs": [],
   "source": [
    "# Build a doc2vec model\n",
    "# YOUR CODE HERE\n",
    "des_model = Doc2Vec(vector_size=100, window=15, min_count=5, max_vocab_size=1000, epochs=1)\n",
    "des_model.build_vocab(des_documents)\n",
    "des_model.train(des_documents, total_examples=des_model.corpus_count, epochs=des_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvwRTr6ueRS4"
   },
   "source": [
    "**[5pts]2.4.2** Find the most similar product for Canon EOS 5D (asin:B0007Y791C) not made by Canon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "wrQZo-AleN-O"
   },
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Ild0RccPeVU3"
   },
   "outputs": [],
   "source": [
    "def read_product_title(fname):\n",
    "    '''\n",
    "    Load all product descriptions\n",
    "    Args: \n",
    "        fname: dataset file path\n",
    "    Returns:\n",
    "        dict: key is asin, value is title of the product\n",
    "    '''\n",
    "    result = {}\n",
    "    for i in parse(fname):\n",
    "        try:\n",
    "            if \"Camera & Photo\" in i[\"categories\"][0]:\n",
    "                result[i[\"asin\"]]=i['title']\n",
    "        except:\n",
    "            continue\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "7pXO7Uyn4klj"
   },
   "outputs": [],
   "source": [
    "product_titles = read_product_title(\"meta_Electronics.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "YkxDSLvM4koj"
   },
   "outputs": [],
   "source": [
    "def find_similar_product_not_by_canon(base_product_id):\n",
    "    product_similarity = des_model.dv.most_similar(base_product_id, topn=1000)\n",
    "    for product_id in product_similarity[0]:\n",
    "        if 'canon' not in product_titles[product_id].lower():\n",
    "            return product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "FnQzlu6S4oJm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B001BP1YEE'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_product_not_by_canon('B0007Y791C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
